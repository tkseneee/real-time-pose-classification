{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b34cd8-856c-4542-9d78-f8abcc327da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# Load the YOLOv8 pose model\n",
    "model = YOLO(\"yolov8n-pose.pt\")\n",
    "\n",
    "# Open the video file and set FPS\n",
    "cap = cv2.VideoCapture(\"my_vid1.mp4\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_num = 0\n",
    "\n",
    "# Get frame dimensions from the input video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Initialize VideoWriter for output video\n",
    "output_filename = \"output_pose_classification.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "writer = cv2.VideoWriter(output_filename, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Dictionaries for storing previous detections and smoothing history per detection index\n",
    "prev_detections = {}\n",
    "state_history = {}\n",
    "history_window = 3  # Number of frames used for temporal smoothing\n",
    "\n",
    "def classify_pose_from_keypoints(keypoints, previous_keypoints=None, velocity_threshold=50):\n",
    "    \"\"\"\n",
    "    Classify the pose using a combination of static keypoint features and dynamic rate of change.\n",
    "    \n",
    "    Static analysis first checks if the person is \"Lying\" or \"Sitting\" based solely on joint positions.\n",
    "    If neither condition is met and previous keypoints are available, the function calculates the\n",
    "    average velocity (from hip, knee, and ankle centers). If that velocity exceeds the threshold,\n",
    "    the pose is flagged as \"Walking\". Otherwise, it defaults to \"Standing\".\n",
    "    \n",
    "    Parameters:\n",
    "        keypoints (np.array): [17, 3] array containing current keypoints (COCO order).\n",
    "        previous_keypoints (np.array or None): Previous frame's keypoints for dynamic comparison.\n",
    "        velocity_threshold (float): Velocity threshold (pixels per second) for \"Walking\".\n",
    "\n",
    "    Returns:\n",
    "        str: Predicted pose (\"Lying\", \"Sitting\", \"Walking\", or \"Standing\").\n",
    "    \"\"\"\n",
    "    kp = np.array(keypoints)[:, :2]  # Use only the (x, y) positions\n",
    "    try:\n",
    "        # Calculate static joint positions:\n",
    "        shoulder_y = np.mean([kp[5][1], kp[6][1]])\n",
    "        hip_y      = np.mean([kp[11][1], kp[12][1]])\n",
    "        knee_y     = np.mean([kp[13][1], kp[14][1]])\n",
    "        ankle_y    = np.mean([kp[15][1], kp[16][1]])\n",
    "        \n",
    "        hip_shoulder_diff = hip_y - shoulder_y\n",
    "        knee_hip_diff     = knee_y - hip_y\n",
    "        ankle_knee_diff   = ankle_y - knee_y\n",
    "        body_height       = ankle_y - shoulder_y\n",
    "        \n",
    "        # PRIORITY 1: Check if the person is lying:\n",
    "        if body_height < 20 and hip_shoulder_diff < 40:\n",
    "            return \"Lying\"\n",
    "        \n",
    "        # PRIORITY 2: Check if the person is sitting:\n",
    "        # Criteria: a low hip-to-shoulder difference (< 60) and a high ankle-to-knee difference (> 40)\n",
    "        if hip_shoulder_diff < 60 and ankle_knee_diff > 40:\n",
    "            return \"Sitting\"\n",
    "        \n",
    "        # PRIORITY 3: Use dynamic (velocity) cues if previous keypoints exist.\n",
    "        if previous_keypoints is not None and previous_keypoints.shape[0] >= 17:\n",
    "            prev_kp = np.array(previous_keypoints)[:, :2]\n",
    "            prev_hip_center = np.mean([prev_kp[11], prev_kp[12]], axis=0)\n",
    "            prev_knee_center = np.mean([prev_kp[13], prev_kp[14]], axis=0)\n",
    "            prev_ankle_center = np.mean([prev_kp[15], prev_kp[16]], axis=0)\n",
    "            \n",
    "            current_hip_center = np.mean([kp[11], kp[12]], axis=0)\n",
    "            current_knee_center = np.mean([kp[13], kp[14]], axis=0)\n",
    "            current_ankle_center = np.mean([kp[15], kp[16]], axis=0)\n",
    "            \n",
    "            # Calculate displacements between frames\n",
    "            disp_hip = np.linalg.norm(current_hip_center - prev_hip_center)\n",
    "            disp_knee = np.linalg.norm(current_knee_center - prev_knee_center)\n",
    "            disp_ankle = np.linalg.norm(current_ankle_center - prev_ankle_center)\n",
    "            \n",
    "            # Calculate velocities (pixels per second)\n",
    "            velocity_hip = disp_hip * fps\n",
    "            velocity_knee = disp_knee * fps\n",
    "            velocity_ankle = disp_ankle * fps\n",
    "            avg_velocity = (velocity_hip + velocity_knee + velocity_ankle) / 3\n",
    "            \n",
    "            if avg_velocity > velocity_threshold:\n",
    "                return \"Walking\"\n",
    "        \n",
    "        # Default fallback:\n",
    "        return \"Standing\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error in classification:\", e)\n",
    "        return \"Unknown\"\n",
    "\n",
    "def compute_sitting_angle(keypoints):\n",
    "    \"\"\"\n",
    "    Computes the angle at the hip joint (in degrees) for a sitting posture.\n",
    "    The angle is defined at the hip between the line connecting the hip center to the shoulder center,\n",
    "    and the line connecting the hip center to the knee center.\n",
    "    \n",
    "    The hip center is the average of the left and right hip points (indices 11 and 12),\n",
    "    shoulder center is the average of points at indices 5 and 6, and\n",
    "    knee center is the average of points at indices 13 and 14.\n",
    "    \n",
    "    Returns:\n",
    "        float: The computed angle at the hip, in degrees.\n",
    "    \"\"\"\n",
    "    kp = np.array(keypoints)[:, :2]\n",
    "    \n",
    "    # Compute centers\n",
    "    hip_center = np.mean([kp[11], kp[12]], axis=0)\n",
    "    shoulder_center = np.mean([kp[5], kp[6]], axis=0)\n",
    "    knee_center = np.mean([kp[13], kp[14]], axis=0)\n",
    "    \n",
    "    # Compute vectors from the hip\n",
    "    vector_shoulder = shoulder_center - hip_center\n",
    "    vector_knee = knee_center - hip_center\n",
    "    \n",
    "    # Calculate the angle between the two vectors using the dot product\n",
    "    dot_product = np.dot(vector_shoulder, vector_knee)\n",
    "    norm_shoulder = np.linalg.norm(vector_shoulder)\n",
    "    norm_knee = np.linalg.norm(vector_knee)\n",
    "    \n",
    "    if norm_shoulder == 0 or norm_knee == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    cos_angle = np.clip(dot_product / (norm_shoulder * norm_knee), -1.0, 1.0)\n",
    "    angle_rad = np.arccos(cos_angle)\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_num += 1\n",
    "    # Use a detection confidence threshold of 0.5\n",
    "    results = model.predict(frame, conf=0.5, verbose=False)\n",
    "    annotated_frame = results[0].plot()\n",
    "    keypoints_data = results[0].keypoints.data.cpu().numpy()  # Expected shape: [num_persons, 17, 3]\n",
    "    \n",
    "    for i, keypoints in enumerate(keypoints_data):\n",
    "        if keypoints.shape[0] < 17:\n",
    "            #print(f\"[Frame {frame_num}, Person {i}] Incomplete keypoints, skipping detection.\")\n",
    "            continue\n",
    "\n",
    "        # Retrieve previous keypoints for temporal dynamics (if available)\n",
    "        prev_kp = prev_detections.get(i, None)\n",
    "        # Classify the pose\n",
    "        current_prediction = classify_pose_from_keypoints(keypoints, previous_keypoints=prev_kp, velocity_threshold=50)\n",
    "        # Update previous detection for this index\n",
    "        prev_detections[i] = keypoints\n",
    "        \n",
    "        # Maintain a short history for smoothing (using majority voting)\n",
    "        if i not in state_history:\n",
    "            state_history[i] = []\n",
    "        state_history[i].append(current_prediction)\n",
    "        if len(state_history[i]) > history_window:\n",
    "            state_history[i].pop(0)\n",
    "        final_pose = collections.Counter(state_history[i]).most_common(1)[0][0]\n",
    "        \n",
    "        # Determine text placement using the nose keypoint if available,\n",
    "        # otherwise fallback to the midpoint of the shoulder keypoints.\n",
    "        try:\n",
    "            nose_x, nose_y = keypoints[0][:2]\n",
    "            if nose_x == 0 or nose_y == 0:\n",
    "                raise ValueError(\"Invalid nose coordinates\")\n",
    "        except Exception:\n",
    "            nose_x = np.mean([keypoints[5][0], keypoints[6][0]])\n",
    "            nose_y = np.mean([keypoints[5][1], keypoints[6][1]])\n",
    "        \n",
    "        # Draw the main pose label on the first line\n",
    "        text_position = (int(nose_x), int(nose_y) - 5)\n",
    "        cv2.putText(annotated_frame, final_pose, text_position,\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        # If the pose is sitting, compute and display the sitting angle (at the hip) on the next line\n",
    "        if final_pose == \"Sitting\":\n",
    "            angle = compute_sitting_angle(keypoints)\n",
    "            # Offset the y coordinate for the second line (e.g., 25 pixels below the first line)\n",
    "            text_position2 = (int(nose_x)-85, int(nose_y) + 15)\n",
    "            cv2.putText(annotated_frame, f\"Angle: {angle:.1f}deg\", text_position2,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    \n",
    "    # Write annotated frame to output video\n",
    "    writer.write(annotated_frame)\n",
    "    \n",
    "    cv2.imshow(\"Pose Classification\", annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Output video saved as {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
